---
title: "Ex-post Survey Data Harmonization Toolbox"
author: "Marta Kołczyńska"
date: "3/23/2019"
csl: "citation_styles/apa.csl"
output:
  bookdown::pdf_document2: default
  bookdown::html_document2: default
bibliography: "C:/Users/mkolc/Google Drive/library.bib"
---

```{r setup, warning=FALSE, message=FALSE, echo = FALSE}
library(essurvey) # getting European Social Survey data
library(tidyverse) # data cleaning and reshaping
library(countrycode) # converting country codes to names
library(ggplot2) # plots

library(knitr)
library(kableExtra)
```


# Abstract

Ex-post harmonization of survey data creates new opportunities for research by extending the geographical and/or time coverage of analyses. While an increasing number of scholars combine different survey projects to analyze them as a single dataset, there is substantial variation in the understanding of what ex-post harmonization entails, and with regard to the methods of data processing and documentation. In this paper I propose a procedure and a set of simple tools for the exploration, recoding, and documentation of harmonization of survey data, relying on the programming language R and Excel spreadsheets - both common software among social scientists. This approach combines automation for improved reproducibility and efficiency, with human decision-making that allows for flexibility necessary in dealing with the variation and diverse standard observed in survey datasets. The resulting documentation of the harmonization process is user-friendly and readible without the knolwedge of any programming language. Variables on trust in institutions from three cross-national survey projects serve as an illustrate of the proposed workflow.



# Introduction

With extensive data archives in place and further archiving efforts in progress, the focus on combining and merging of existing data in order to build on what had already been done seems to be the optimal strategy and logical next step of developing the research infrastructure, and has already received supportive recognition [@Burkhauser2005]. 

International, and even multi-wave, survey projects are a major advancement in the social science infrastructure for cross-national research, yet their country and time coverage remains necessarily limited by funding availability, organizational conditions, and PIs' interests. Ex-post harmonization of survey data promises to overcome these limitations to create larger datasets with more global coverage. At the same time, ex-post harmonization can create country time series necessary for longitudinal analyses, which enables stronger tests of theoretical mechanisms than cross-country comparisons. Thus, harmonization of existing data in order to maximally exploit their potential for research is one of the major challenges in the social sciences. While the promises of new research opportunities are alluring to many, the associated challenges are multi-faceted - including technical, logistical, methodological, and substantive - and not yet well understood. This paper addresses one of these challenges, concerning the organization and documentation of the ex-post survey data harmonization process in a way that enables reproducibility of all data processing, as well as the cumulative character of harmonization efforts.

The number of projects relying on combined data from different cross-national survey projects is increasing. These projects range from small initiatives where the multi-projects dataset is created for the purposes of a single publication or dissertation [e.g., @Christmann2018; @Christmann2018a; @Mauk2019] to large projects performing ex-post survey data harmonization not - or not only - for own substantive research, but in order to improve the social science research infrastructure [@Bekkers2015; @Klassen2018; @Slomczynski2018]. Correspondingly, the effort invested in the creation and sharing of the documentation of the harmonization process is characterized by substantial variation. 

The diversity of approaches to documenting the harmonization process reflects the lack of established and followed standards for computational reproducibility, i.e. the ability to re-create the results of published research using materials - data and code - provided by the authors of the original study [cf. @Liu2019]. The value of published research largely depends on its reproducilibity [@Buckheit1995]. In addition to data and code, researchers are starting to recognize the role of the programming environment in reproducibility of results both currently, and in the near and more distant future. For example, @Liu2019 propose to use software containers (such as Docker) to standardize the software and cloud computing (such as Amazon Web Services) to standardize the hardware, especially in computation-intensive analyses.

Reproducibility not only concerns research publications, but also processed data, such as those resulting from ex-post survey data harmonization products, although in this case it might be more accurately called 'data processing reproduciblity', thus excluding data modeling. 

In this paper I propose a procedure and a set of simple tools for the exploration, recoding, and documentation of harmonization of survey data, relying on crosswalks for mapping one coding scheme onto another. The proposed approach includes automated steps that ensure reproducibility and efficiency of data processing, with human decision-making to integrate methodological expertise and domain knowledge, and enable flexibility necessary in dealing with the variation and diverse standard observed in survey datasets.
The product of the harmonization process is its documentation in form of crosswalk tables that map (1) source variables to target variables and (2) source values to target values. The human-friendly character and readibility of crosswalks enables the verification and reproduction of the harmonization process. 

The example presented in this paper uses the programming language R and Excel spreadsheets - both common software among social scientists. The general framework combining recoding syntax and spreadsheets is software-agnostic and can be used with any programming language. Survey variables on trust in institutions from three cross-national survey projects - the European Social Survey, the European Values Study, the European Quality of Life Survey - serve as an illustration of the proposed workflow.

This work builds on the experiences of four inter-related projects: (1) the *Democratic Values and Protest Behavior: Data Harmonization, Measurement Comparability, and Multi-Level Modeling* project funded by the (Polish) National Science Centre (2012/06/M/HS6/00322, 2013-2016), its continuation *Survey Data Recycling: New Analytic Framework, Integrated Database, and Tools for Cross-national Social, Behavioral and Economic Research* funded by the U.S. National Science Foundation (2017-2021, PTE Federal award 1738502), (3) *New Approach to Analyses of the Relationship between Democracy and Trust: Comparing European Countries Using Quantitative and Qualitative Methodology* funded by the (Polish) National Science Centre (2012/05/N/HS6/03886, 2013-2015), (4) *Stratified modernity, trust in state institutions and democratic change in cross-national perspective: using harmonized survey data from 116 countries* project supported by the Silverman Research Support Award from the Department of Sociology, The Ohio State University (2017), and (5) *Effects of status inconsistency on political values, attitudes and behavior: a cross-national analysis with survey data harmonized ex post*, funded by the Institute of Philosophy and Sociology, Polish Academy of Science (2017/S/05, 2018). 

The proposed procedures are substantially simplified compared to those implemented in the aforementioned projects in the spirit of accessibility and reproducibility, and the harmonization tools were developed independently. Altogether, the workflow proposed in this paper is sufficiently simple that it can be successfully implemented by a single person or a small team of programming non-specialists, and powerful enough that it can handle large amounts of data and harmonization situations of moderate complexity, with highly complex cases possible to accomodate after some modifications. 



# What is ex-post survey data harmonization?

Ex-post survey data harmonization refers to procedures applied to survey data sets that were not intended for joint analysis, in order to construct a single dataset that can be meaningfully employed in substantive analyses [cf. @Dubrow2016].

The harmonization process is simultaneously theory-informed and data-driven. Theories provide the concepts to be measured, but data availability to a large extent determines what ends up being measured and how. The following steps can be distinguished [cf. @Granda2016; @Wolf2016; @Kolczynska2019]:

(1)	concept definition: 
    a.	defining the concept of interest guided by the theoretical framework and hypotheses; 
    b.	based on this definition, developing a preliminary coding scheme or choosing a coding scale for the harmonized (target) variable;
(2)	data preparation: 
    a.	gathering available surveys (data and documentation) that meet the requirements regarding the topics, target population and representativeness, and potentially others;
    b.	exploring the methodological variation they represent with regard to the design of the survey items of interest and the overall survey process; 
    c.	describing surveys in terms of methodology, including quality (and potentially exclude some surveys on this basis), and constructing survey quality indicators;
    d.	identifying relevant items in the gathered surveys that correspond to the target concept(s);
    e.	describing the methodological variation in the design of the selected survey items given the research of survey methodology and effects of item design on respondents’ answers (potentially exclude some items in this step);
    f.	identifying relevant dimensions of variation between the survey items to be captured by harmonization control variables;
    g.	adjusting the coding scheme or scale of the harmonized (target variable) based on the observed variation in the survey items;
(3)	harmonization: 
    a.	transforming source variables into the target variable(s) using the coding scheme;
    b.	constructing harmonization control variables to capture the properties of source variables that would be lost in the process of recoding;
(4)	checking the target variable for errors and documentation of the whole process.



## Ex-post survey data harmonization projects: A non-exhaustive review

Researchers increasingly combine data from multiple survey projects to fill in the gaps in geographical coverage, or to increase the presence of typically underrepresented countries, e.g. autocracies or countries from the Global South. Identifying projects that turn to ex-post survey data harmonization is not easy, because the term "ex-post harmonization" is not often used. This section briefly describe the approaches taken in a non-representative sample of ex-post survey data harmonization projects. The number of publications relying on survey data harmonized ex-post is difficult to know, because the term "ex-post survey data harmonization" is not widely used as the name of this procedure. An alternative term, "integrative data analysis", proposed by @Curran2009, has not caught on either.

Based on a non-systematic review of ex-post survey data harmonization projects, two broad categories can be distinguished: small-scale projects where harmonization is performed for the purposes of a single paper or dissertation, and large-scale projects that enable multiple different analyses with the general aim of improving the social science research infrastructure.


### Small-scale projects

The two small-scale projects I identified, ex-post survey data harmonization provided data for dissertation research. The first project [@Christmann2018; @Christmann2018a] harmonized data from several cross-national and national survey projects. The selection criterion for the projects was a particular design of the satisfaction with democracy question, which was the key variable in the analysis: only surveys where a four-point response scale was used were harmonized [@Christmann2018; @Christmann2018a]. Replication materials that accompany the paper, available from Harvard's Dataverse, include the final harmonized data file and code for conducting the analysis, but no harmonization syntax (https://doi.org/10.7910/DVN/EU541C).

The second project deals with political trust and democratic values, and relies on data from six cross-national survey projects from a hundred countries and almost global coverage [@Mauk2019]. Replication materials, also stored on Dataverse, include a recoding syntax file with all the code necessary to create the harmonized variables used in subsequent analyses. The harmonized dataset is not provided (https://doi.org/10.7910/DVN/IIVAJM).


### Infrastructure projects

There are at least three large-scale projects that perform ex-post survey data harmonization. The first one is the Democratic Values and Protest Behavior (DVPB) project [@Slomczynski2018, @Slomczynskietal2016], which harmonized selected variables on political participation, political trust, and basic socio-demographics, from 22 major international survey projects between 1966 and 2013. The data are publicly available via Harvard's Dataverse: https://doi.org/10.7910/DVN/VWGF5Q
The project, now completed, used a suite of open-source tools for extracting source data, applying the harmonization procedures, and outputting data files in a format usable by social scientists. The programming environment is based on scripting tools, while data processing occurs in a MariaDB database. The publicly available documentation consists of codebooks, recode syntax in SQL and lists of source variable names selected for harmonization from each dataset. 
The continuation of this initiative, the Survey Data Recycling project (dataharmonization.org), will extend the set of harmonized variable to also include social capital and well-being indicators, and update the data up until 2017.

The second project, Human Understanding Measured Across National Surveys (HUMANS, humansurveys.org) uses data from 19 cross-national and national survey projects, many of them the same as in the previous project, and harmonized variables on social trust, satisfaction with democracy, support for democracy, and perceived electoral integrity, as well as basic socio-demographics. The data are also available on Dataverse: https://dataverse.harvard.edu/dataverse/humansurveys
In terms of documentation, the codebook [@Klassen2018] provides the recodes from source to target coding schemes, names of source variables, and names of source data files, all in a PDF document.

The third initiative, the Harmonized Trust Database created by the Global Trust Research Consortium (GTRC) (globaltrustresearch.wordpress.com), contains data from 79 national and cross-national survey projects, covering 155 countries since 1953. The project Open Science Framework profile (https://osf.io/qfv76/) provides a PDF codebook [@Sandberg2018] with names of source projects, but without data file versions or source variable names. The harmonized data are not publicly available.

The three projects have very similar goals and scopes - in terms of the type of source data and the substantive interest in harmonizing particular variables - and yet, their approaches to documenting the harmonization, and the extent the harmonization is reproducible, are very different. While the DVPB project published voluminous documentation, in practice the exact replication of all harmonization procedures would most likely not be straightforward, despite the natural language-resembling nature of SQL, due to complications with re-creating the software environment. The HUMANS project published source and target variables, but the recoding schema is provided in a PDF document - not the most machine-readable format. GTRC provides neither the recode schemas, nor the resulting data.  

The three large project described in this section also have one other thing in common: with the data and documentation made public by these projects it is not possible to extend the dataset by adding extra harmonized target variables.  The reason is that the two projects that provide the harmonized data - DVPB and HUMANS - do not include original respondent (case) IDs from the source data files, so even though it is possible to construct additional variables separately, it is impossible to match them to the already harmonized data.

# The proposed workflow

In the proposed workflow harmonization documentation is a product of the harmonization process itself. This section describes the harmonization steps and associated tools, to provide an overview of the whole process.

The procedure starts with all the source data files downloaded to a single location, and their origin and versions noted. Next, each source data file is imported to R, and inspected to create the following technical variables: source case ID, target case ID (row number in the data file), survey project, survey wave/round identifier, survey year, survey country, and case weights.

In terms of data processing, the harmonization work involves working with data at different levels. For each of these steps, a corresponding table is created on the basis of the source data, and exported to Excel for manual mapping. The resulting crosswalks are used in the next step of harmonization, and at the same time serve as documentation.

Crosswalks are commonly used tools for mapping of one schema onto the other. They are most useful when the source schema can be unambiguously translated into the target schema. This is rarely the case as exemplified by the many examples of class schemas developed in the social sciences. Also in the process of ex-post survey data harmonization, in some cases the mapping is not straightforward and decisions, sometimes arbitrary, need to be made. Like in other cases, also here, "[T]he key to a successful metadata crosswalk is intelligent flexibility" [@Hillmann2004, p. 91]. This is why the mapping is performed manually. Given the typical number of variables harmonized, this should not be an excessive effort.




Step 1: Selection of source variables for harmonization,  
Step 2: Mapping source values to target values,  
Step 3: Recording characteristics of source items.  

The first step is at the variable level, and involves identifying variables for harmonization in the source data files, and assigning a standardized target variable name to each source variable of interest. To do this, a table with a list of all source variables is created on the basis of metadata from the source data files, and includes variable names, labels, as well as values and value labels and their corresponding frequencies. Each variable corresponds to a single row in the resulting table, which I refer to as the *codebook*. The codebook is then exported to Excel (or other spreadsheet program), where variable lables are filtered to inentify candidates for source variables. In some cases, for example is variable labels are too short or otherwise uninformative - the original survey documentation needs to be consulted. After all source variables corresponding to the concept of interest - in this case trust in institutions - are identified via filter searches or otherwise, the table is imported back into R.

The second step is at the level of individual values of the source variables, and requires mapping these source values onto a common coding scheme of the respective target variable. Subsets of source data files are selected that include only the variables tagged in Step 1. For those variables, a *cross-walk table* is created, i.e., a table similar to the codebook, but where each source value corresponds to one row. This table is then exported to a spreadsheet, where each source value is assigned a target value on the basis of the common coding scheme. This step also includes identifying missing value codes (such as negative numbers or multiples of 8 or 9) as missing. Next, the cross-walk table is imported back to R, where the source and target values for each source variable are mapped resulting in the harmonized variables.

The third step is at the data file level, and refers to the coding of properties of the source variables that are worth preserving because of methodological reasons, such as the length or direction of the original response scales. Typically, these properties vary between, but not within, survey projects. For example, in the European Social Survey, questions about trust in institutions are accompanied by 11-point scales ranging from 0 (No trust at all) to 10 (Completely trust) [@ESSEuropeanSocialSurvey2016b]. 


# Illustration: Trust in institutions

Trust in political and other institutions is a common item in many cross-national surveys. For researchers interested in analyzing trust in a comparative perspective, it is important to know which projects include which trust items in which waves and countries, i.e., how rich a dataset they can count on.

The source data in this example include three cross-national survey projects carried out in Europe: The European Social Survey, the European Values Study, and the European QUality of Life Survey. The data are available from the project website, the GESIS archive, and the UK Data Archive, respectively. Table \@ref(tab:project-table) presents basic information about these survey projects.

```{r project-table, warning=FALSE, message=FALSE, echo = FALSE}

ESS <- c("European Social Survey (ESS)", "8", "1", "195", "2002-2017")
EQLS <- c("European Quality of Life Survey (EQLS)", "4", "1", "126", "2003-2016")
EVS <- c("European Values Study (EVS)", "4", "2", "140", "1981-2017")

rbind.data.frame(ESS, EQLS, EVS, stringsAsFactors=FALSE) %>%
  kable(col.names = c("Project name", "Number of waves", "Number of data files", 
                      "Number of surveys", "Years"),
        caption="Description of the survey projects.") %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left") %>%
  column_spec(1, width = "20em") %>%
  column_spec(2:4, width = "5em")


```

## Step 1: Selection of source variables for harmonization


## Step 2: Mapping source values to target values


## Step 3: Recording characteristics of source items


# References

